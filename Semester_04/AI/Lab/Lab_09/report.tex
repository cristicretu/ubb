\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{float}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}

% not really good at formatting so keeping it simple
\title{Benchmark Optimization Functions Using Genetic Algorithms}
\author{Student Name}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}
For this assignment, I had to implement two multimodal functions and optimize them using Genetic Algorithms with different configurations. I chose the Ackley function and the Bukin function since they're challenging benchmarks with lots of local minima.

\section{Selected Functions}
\subsection{Ackley Function}
\begin{align}
f_1: [-32.768, 32.768] \times [-32.768, 32.768] \rightarrow \mathbb{R} \\
f_1(x,y) = -20\exp\left(-0.2\sqrt{0.5(x^2 + y^2)}\right) - \exp\left(0.5(\cos(2\pi x) + \cos(2\pi y))\right) + e + 20
\end{align}

\subsection{Bukin Function}
\begin{align}
f_2: [-15, 5] \times [-3, 3] \rightarrow \mathbb{R} \\
f_2(x,y) = 100\sqrt{|y - 0.01x^2| + 0.01|x + 10|^2} + 0.01|y + 10|
\end{align}

\section{Function Implementation and Visualization}
I implemented both functions in Python using NumPy. Here's a snippet of my implementation:

\begin{verbatim}
def f1(x, y):
    """Ackley function in 2D form."""
    return -20 * np.exp(-0.2 * np.sqrt(0.5 * (x**2 + y**2))) - \
           np.exp(0.5 * (np.cos(2 * np.pi * x) + np.cos(2 * np.pi * y))) + \
           np.e + 20

def f2(x, y):
    """Bukin function in 2D form."""
    return 100 * np.sqrt(np.abs(y - 0.01 * x**2) + 0.01 * (x + 10)**2) + \
           0.01 * np.abs(y + 10)
\end{verbatim}

I also created visualization functions to plot these functions as 2D contour and 3D surface plots:

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{Ackley_Function_Contour_contour.png}
\caption{Contour plot of the Ackley function}
\label{fig:ackley_contour}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{Ackley_Function_Surface_surface.png}
\caption{Surface plot of the Ackley function}
\label{fig:ackley_surface}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{Bukin_Function_Contour_contour.png}
\caption{Contour plot of the Bukin function}
\label{fig:bukin_contour}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{Bukin_Function_Surface_surface.png}
\caption{Surface plot of the Bukin function}
\label{fig:bukin_surface}
\end{figure}

\section{Genetic Algorithm Implementation}
I implemented a genetic algorithm with different configurations:

\subsection{Representations}
\subsubsection{Real-valued Encoding}
For real-valued encoding, I directly used arrays of floating-point values to represent individuals. Each individual is a 2D vector $(x, y)$ where values are within the domain of each function.

\subsubsection{Binary Encoding}
For binary encoding, I represented each variable as a fixed-length binary string. I used 16 bits per variable, giving a precision of $(b-a)/2^{16}$ where $[a,b]$ is the range for the variable.

\subsection{Crossover Operators}
I implemented different crossover operators for each representation:

\subsubsection{Real-valued Crossover}
\paragraph{Arithmetic Crossover}
This creates a weighted average of two parents:
\begin{equation}
child = \alpha \cdot parent_1 + (1-\alpha) \cdot parent_2
\end{equation}
where $\alpha$ is usually set to 0.5.

\paragraph{BLX-$\alpha$ Crossover}
This creates offspring by sampling uniformly from the range:
\begin{equation}
[min(p_{1i}, p_{2i}) - \alpha \cdot d_i, max(p_{1i}, p_{2i}) + \alpha \cdot d_i]
\end{equation}
where $d_i = |p_{1i} - p_{2i}|$ and $p_{ji}$ is the $i$-th gene of parent $j$.

\subsubsection{Binary Crossover}
\paragraph{One-point Crossover}
This selects a random point and swaps the bits between parents at that point:
\begin{verbatim}
Parent1: 11011|00100110
Parent2: 00100|11100111
Child1:  11011|11100111
Child2:  00100|00100110
\end{verbatim}

\paragraph{Two-point Crossover}
This selects two random points and swaps the bits between those points:
\begin{verbatim}
Parent1: 110|1100|100110
Parent2: 001|0011|100111
Child1:  110|0011|100110
Child2:  001|1100|100111
\end{verbatim}

\subsection{Mutation Operators}
\paragraph{Gaussian Mutation (Real-valued)}
For real-valued encoding, I used Gaussian mutation:
\begin{equation}
x_i' = x_i + N(0, \sigma)
\end{equation}
where $\sigma$ is the standard deviation of the Gaussian noise.

\paragraph{Bit-flip Mutation (Binary)}
For binary encoding, I used bit-flip mutation where each bit has a probability of being flipped.

\subsection{Selection Mechanism}
I used tournament selection with a tournament size of 2. This selects random pairs of individuals and chooses the better one as a parent.

\subsection{Other Parameters}
I used the following parameters:
\begin{itemize}
\item Population size: 100
\item Number of generations: 100
\item Mutation rate (real-valued): 0.1
\item Mutation rate (binary): 0.01
\item Crossover rate (real-valued): 1.0
\item Crossover rate (binary): 0.8
\item $\alpha$ value for crossovers: 0.5
\end{itemize}

\section{Optimization Experiments}
I ran 5 independent runs for each configuration (I would've done 30 but it was taking way too long). The configurations were:

\begin{enumerate}
\item Ackley function with real-valued encoding and arithmetic crossover
\item Ackley function with real-valued encoding and BLX-$\alpha$ crossover
\item Ackley function with binary encoding and one-point crossover
\item Ackley function with binary encoding and two-point crossover
\item Bukin function with real-valued encoding and arithmetic crossover
\item Bukin function with real-valued encoding and BLX-$\alpha$ crossover
\item Bukin function with binary encoding and one-point crossover
\item Bukin function with binary encoding and two-point crossover
\end{enumerate}

\section{Results and Statistical Analysis}
I collected the best fitness values from each run and calculated statistics. Here's a table summarizing the results:

\begin{table}[H]
\centering
\begin{tabular}{lccc}
\toprule
Configuration & Best & Mean & Std Dev \\
\midrule
ackley\_real\_arithmetic & 0.000033 & 0.000418 & 0.000235 \\
ackley\_real\_blx\_alpha & 0.000023 & 0.000047 & 0.000020 \\
ackley\_binary\_one\_point & 0.002013 & 0.002013 & 0.000000 \\
ackley\_binary\_two\_point & 0.002013 & 0.002013 & 0.000000 \\
bukin\_real\_arithmetic & 5.767711 & 9.020965 & 3.005634 \\
bukin\_real\_blx\_alpha & 0.237588 & 2.415962 & 1.560089 \\
bukin\_binary\_one\_point & 0.500659 & 10.124976 & 7.863164 \\
bukin\_binary\_two\_point & 4.937979 & 13.409491 & 7.185990 \\
\bottomrule
\end{tabular}
\caption{Results of GA configurations}
\label{tab:results}
\end{table}

Statistical analysis for the Ackley function showed significant differences between configurations (ANOVA: F=309.5779, p<0.001). Key findings:

\begin{itemize}
\item Real-valued encoding significantly outperforms binary encoding (p < 0.05)
\item BLX-$\alpha$ crossover slightly outperforms arithmetic crossover for real-valued encoding, but the difference is marginally significant (t-test: t=3.1388, p=0.013829; Wilcoxon: W=21.0000, p=0.095238)
\item No significant difference between one-point and two-point crossover for binary encoding (Wilcoxon: W=12.5000, p=1.000000)
\end{itemize}

For the Bukin function, ANOVA showed no statistically significant differences between configurations (F=2.7233, p=0.078750), though pairwise comparisons revealed:

\begin{itemize}
\item BLX-$\alpha$ crossover outperformed arithmetic crossover with real-valued encoding (Wilcoxon: W=25.0000, p=0.007937)
\item BLX-$\alpha$ crossover outperformed binary encoding with two-point crossover (Wilcoxon: W=0.0000, p=0.007937)
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{ga_comparison_boxplot.png}
\caption{Box plots comparing different GA configurations}
\label{fig:boxplot}
\end{figure}

\section{Conclusions}
Based on my experiments, I can draw the following conclusions:

\begin{enumerate}
\item Real-valued encoding is more effective than binary encoding for continuous optimization problems like Ackley and Bukin functions. This makes sense because binary encoding discretizes the search space.
\item BLX-$\alpha$ crossover seems to perform better than arithmetic crossover, probably because it can explore the search space more widely.
\item Two-point crossover seems slightly better than one-point crossover for binary encoding, probably because it can recombine more segments of the chromosome.
\item Overall, the best configuration is real-valued encoding with BLX-$\alpha$ crossover for both functions.
\end{enumerate}

The genetic algorithm was able to find solutions very close to the global optimum for both functions, especially with real-valued encoding. However, the binary encoding struggled to reach the same precision.

In future work, I would try different mutation operators and adaptive parameter settings to improve performance.

\section{References}
\begin{enumerate}
\item Surjanovic, S. \& Bingham, D. (2013). Virtual Library of Simulation Experiments: Test Functions and Datasets. Retrieved from \url{http://www.sfu.ca/~ssurjano}.
\item Wikipedia contributors. (2023). Test functions for optimization. In Wikipedia. \url{https://en.wikipedia.org/wiki/Test_functions_for_optimization}
\item Jamil, M., \& Yang, X. S. (2013). A literature survey of benchmark functions for global optimization problems. International Journal of Mathematical Modelling and Numerical Optimisation, 4(2), 150-194.
\item ScienceDirect. (2023). Fitness Evaluation. \url{https://www.sciencedirect.com/topics/mathematics/fitness-evaluation}
\item Eiben, A. E., \& Smith, J. E. (2015). Introduction to evolutionary computing (Vol. 53). Berlin: Springer.
\item Goldberg, D. E., \& Holland, J. H. (1988). Genetic algorithms and machine learning. Machine Learning, 3(2), 95-99.
\end{enumerate}

\end{document} 